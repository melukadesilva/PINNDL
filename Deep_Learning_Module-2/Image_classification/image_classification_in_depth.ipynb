{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.0 64-bit ('tf_env')",
   "metadata": {
    "interpreter": {
     "hash": "24c09eb12affc39a48e537981c24ee3cfd2ae77e66ee4374c7e4829640463172"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image"
   ]
  },
  {
   "source": [
    "# IMAGE CLASSIFICATION IN DEPTH"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Content\n",
    "\n",
    "1. Image classification metrics\n",
    "    1. Binary and multiclass classification\n",
    "    1. Softmax function\n",
    "    2. Cross entropy loss function\n",
    "    3. Confusion matrix\n",
    "    4. Accuracy, precision recall\n",
    "    5. Receiver Operating Characteristic (ROC) curve\n",
    "\n",
    "2. Transfer learning in image classification\n",
    "    1. Introduction to transfer learning in deep learning\n",
    "    2. Transfer learning experiment setup\n",
    "    3. Experiment results and discussion\n",
    "\n",
    "3. Practical example of image classification in Kaggle"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 1. Image classification metrics\n",
    "\n",
    "### 1.1 Binary and Multicalss classification\n",
    "\n",
    "#### Binary\n",
    "\n",
    "* Binary classification address the case where the label is either \"True\" or \"False\"\n",
    "\n",
    "    * The activation used in binary is the sigmoid function: $\\sigma_{sigmoid}(x) = \\dfrac {1}{1 + e^{-x}}$ \n",
    "\n",
    "    * The sigmoid calculated the independent probabilities\n",
    "\n",
    "    * Sum of all sigmoid outputs does not necessarily adds up to 1.0\n",
    "\n",
    "    * A solid decision on a prediction can be found by thresholding the outputs\n",
    "        * $output = 1$ if $prob > threshold$ else $0$\n",
    "\n",
    "#### Multicalss\n",
    "\n",
    "* Multicalss addresses the case with more than 2 classes\n",
    "\n",
    "    * The activation function used in this case is the Softmax function ($f$)\n",
    "    * A solid decision on the predicted class is made by taking the class that max the probability\n",
    "        \n",
    "        * $output = argmax_{i \\in [i...N]}(f_i(x))$\n",
    "\n",
    "        * The decision would be the class with highest confidence"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### 1.2 Softmax function\n",
    "\n",
    "* A deep learning model at the output layer, outputs classification logits (unnormalized)\n",
    "\n",
    "* The Softmax function normalizes these logits to a discrete probability distribution by taking the dependent probabilities of the logits\n",
    "\n",
    "    * $f(z)_i = \\dfrac {e^{z_i}} {\\sum_{j=1}^N e^{z_j}}$\n",
    "    * where $z$ is the output logits and $i$ is the class we consider out of $N$ classes"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[0.004515676666643495,\n",
       " 0.016569357344960955,\n",
       " 0.07425870771543724,\n",
       " 0.9046562582729584]"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "import numpy as np\n",
    "logits = [0.3, 1.6, 3.1, 5.6]\n",
    "softmax = lambda z, zs: np.exp(z) / sum(np.exp(zs))\n",
    "norm_logits = list(map(lambda z: softmax(z, logits), logits))\n",
    "norm_logits"
   ]
  },
  {
   "source": [
    "### 1.3 Cross entropy loss function\n",
    "\n",
    "* Take an input image $x$ (a random variable), true label distribution $P(x)$ and model prediction distribution $Q(x)$\n",
    "\n",
    "    * The information in a given event quantifies the amount of uncertainty in that event\n",
    "\n",
    "        * Deterministic events carry very less information (uninformative) (e.g. Sun rose today)\n",
    "        * Less likely events carries more information (e.g. Today there was an eclips)\n",
    "        * Information (self) a random variable carries: $I(x) = -log(P(x))$\n",
    "        * When $log$ is base $e$, the unit of information measurement is nats and bits or shannons for the base $2$\n",
    "\n",
    "    * The entropy quantifies the uncertainty of a given distribution (expected amount of information)\n",
    "        * Near deterministic distributions have zero entropy and uniform distributions have very high entropy\n",
    "        * Entropy (amount of self information) of a distribution: $H(x) = \\mathbb E_{x \\sim P} [-log(p(x))] = -\\sum_{i=0}^{K}[P(x_i)log (P(x_i))]$\n",
    "\n",
    "    * Taking the same idea, cross entropy measures the difference between a true distribution P(x) and an estimated distribution Q(x)\n",
    "        * Cross entropy loss: $H(p,q) = -\\sum_x P(x)log(Q(x))$\n",
    "        \n",
    "    * Cross entropy is always higher than the entropy expected for the case where $Q(x) \\approx P(x)$\n",
    "\n",
    "* Classification example:\n",
    "\n",
    "    * Take: a model outputs $\\sigma(z) = [class 1 = 0.23, class 2 = 0.63, class 3 = 0.14]$ as normalized logits for a given image of $class 2$\n",
    "    * The onehot encoded lable is $[0, 1, 0]$\n",
    "    * The cross entropy for this perticular input:\n",
    "    \n",
    "        * $H = -0 * log(0.23) - 1 * log(0.63) - 0* log(0.13) = 0.462 $\n",
    "\n",
    "* Reference on Cross Entropy Loss:\n",
    "    * http://machinelearningmechanic.com/deep_learning/2019/09/04/cross-entropy-loss-derivative.html\n",
    "    * https://rdipietro.github.io/friendly-intro-to-cross-entropy-loss/\n",
    "        \n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "entropy: 2.455934956273793\ncross entropy: 4.210934130067198\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Created with matplotlib (https://matplotlib.org/) -->\n<svg height=\"248.518125pt\" version=\"1.1\" viewBox=\"0 0 368.925 248.518125\" width=\"368.925pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n <metadata>\n  <rdf:RDF xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n   <cc:Work>\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n    <dc:date>2021-01-10T09:41:32.077988</dc:date>\n    <dc:format>image/svg+xml</dc:format>\n    <dc:creator>\n     <cc:Agent>\n      <dc:title>Matplotlib v3.3.3, https://matplotlib.org/</dc:title>\n     </cc:Agent>\n    </dc:creator>\n   </cc:Work>\n  </rdf:RDF>\n </metadata>\n <defs>\n  <style type=\"text/css\">*{stroke-linecap:butt;stroke-linejoin:round;}</style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M -0 248.518125 \nL 368.925 248.518125 \nL 368.925 0 \nL -0 0 \nz\n\" style=\"fill:none;\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 26.925 224.64 \nL 361.725 224.64 \nL 361.725 7.2 \nL 26.925 7.2 \nz\n\" style=\"fill:#ffffff;\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <defs>\n       <path d=\"M 0 0 \nL 0 3.5 \n\" id=\"ma3f081966e\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"42.143182\" xlink:href=\"#ma3f081966e\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 0.0 -->\n      <g transform=\"translate(34.191619 239.238437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 31.78125 66.40625 \nQ 24.171875 66.40625 20.328125 58.90625 \nQ 16.5 51.421875 16.5 36.375 \nQ 16.5 21.390625 20.328125 13.890625 \nQ 24.171875 6.390625 31.78125 6.390625 \nQ 39.453125 6.390625 43.28125 13.890625 \nQ 47.125 21.390625 47.125 36.375 \nQ 47.125 51.421875 43.28125 58.90625 \nQ 39.453125 66.40625 31.78125 66.40625 \nz\nM 31.78125 74.21875 \nQ 44.046875 74.21875 50.515625 64.515625 \nQ 56.984375 54.828125 56.984375 36.375 \nQ 56.984375 17.96875 50.515625 8.265625 \nQ 44.046875 -1.421875 31.78125 -1.421875 \nQ 19.53125 -1.421875 13.0625 8.265625 \nQ 6.59375 17.96875 6.59375 36.375 \nQ 6.59375 54.828125 13.0625 64.515625 \nQ 19.53125 74.21875 31.78125 74.21875 \nz\n\" id=\"DejaVuSans-48\"/>\n        <path d=\"M 10.6875 12.40625 \nL 21 12.40625 \nL 21 0 \nL 10.6875 0 \nz\n\" id=\"DejaVuSans-46\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"103.015909\" xlink:href=\"#ma3f081966e\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 0.2 -->\n      <g transform=\"translate(95.064347 239.238437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 19.1875 8.296875 \nL 53.609375 8.296875 \nL 53.609375 0 \nL 7.328125 0 \nL 7.328125 8.296875 \nQ 12.9375 14.109375 22.625 23.890625 \nQ 32.328125 33.6875 34.8125 36.53125 \nQ 39.546875 41.84375 41.421875 45.53125 \nQ 43.3125 49.21875 43.3125 52.78125 \nQ 43.3125 58.59375 39.234375 62.25 \nQ 35.15625 65.921875 28.609375 65.921875 \nQ 23.96875 65.921875 18.8125 64.3125 \nQ 13.671875 62.703125 7.8125 59.421875 \nL 7.8125 69.390625 \nQ 13.765625 71.78125 18.9375 73 \nQ 24.125 74.21875 28.421875 74.21875 \nQ 39.75 74.21875 46.484375 68.546875 \nQ 53.21875 62.890625 53.21875 53.421875 \nQ 53.21875 48.921875 51.53125 44.890625 \nQ 49.859375 40.875 45.40625 35.40625 \nQ 44.1875 33.984375 37.640625 27.21875 \nQ 31.109375 20.453125 19.1875 8.296875 \nz\n\" id=\"DejaVuSans-50\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-50\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_3\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"163.888636\" xlink:href=\"#ma3f081966e\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 0.4 -->\n      <g transform=\"translate(155.937074 239.238437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 37.796875 64.3125 \nL 12.890625 25.390625 \nL 37.796875 25.390625 \nz\nM 35.203125 72.90625 \nL 47.609375 72.90625 \nL 47.609375 25.390625 \nL 58.015625 25.390625 \nL 58.015625 17.1875 \nL 47.609375 17.1875 \nL 47.609375 0 \nL 37.796875 0 \nL 37.796875 17.1875 \nL 4.890625 17.1875 \nL 4.890625 26.703125 \nz\n\" id=\"DejaVuSans-52\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-52\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_4\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"224.761364\" xlink:href=\"#ma3f081966e\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 0.6 -->\n      <g transform=\"translate(216.809801 239.238437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 33.015625 40.375 \nQ 26.375 40.375 22.484375 35.828125 \nQ 18.609375 31.296875 18.609375 23.390625 \nQ 18.609375 15.53125 22.484375 10.953125 \nQ 26.375 6.390625 33.015625 6.390625 \nQ 39.65625 6.390625 43.53125 10.953125 \nQ 47.40625 15.53125 47.40625 23.390625 \nQ 47.40625 31.296875 43.53125 35.828125 \nQ 39.65625 40.375 33.015625 40.375 \nz\nM 52.59375 71.296875 \nL 52.59375 62.3125 \nQ 48.875 64.0625 45.09375 64.984375 \nQ 41.3125 65.921875 37.59375 65.921875 \nQ 27.828125 65.921875 22.671875 59.328125 \nQ 17.53125 52.734375 16.796875 39.40625 \nQ 19.671875 43.65625 24.015625 45.921875 \nQ 28.375 48.1875 33.59375 48.1875 \nQ 44.578125 48.1875 50.953125 41.515625 \nQ 57.328125 34.859375 57.328125 23.390625 \nQ 57.328125 12.15625 50.6875 5.359375 \nQ 44.046875 -1.421875 33.015625 -1.421875 \nQ 20.359375 -1.421875 13.671875 8.265625 \nQ 6.984375 17.96875 6.984375 36.375 \nQ 6.984375 53.65625 15.1875 63.9375 \nQ 23.390625 74.21875 37.203125 74.21875 \nQ 40.921875 74.21875 44.703125 73.484375 \nQ 48.484375 72.75 52.59375 71.296875 \nz\n\" id=\"DejaVuSans-54\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-54\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_5\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"285.634091\" xlink:href=\"#ma3f081966e\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 0.8 -->\n      <g transform=\"translate(277.682528 239.238437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 31.78125 34.625 \nQ 24.75 34.625 20.71875 30.859375 \nQ 16.703125 27.09375 16.703125 20.515625 \nQ 16.703125 13.921875 20.71875 10.15625 \nQ 24.75 6.390625 31.78125 6.390625 \nQ 38.8125 6.390625 42.859375 10.171875 \nQ 46.921875 13.96875 46.921875 20.515625 \nQ 46.921875 27.09375 42.890625 30.859375 \nQ 38.875 34.625 31.78125 34.625 \nz\nM 21.921875 38.8125 \nQ 15.578125 40.375 12.03125 44.71875 \nQ 8.5 49.078125 8.5 55.328125 \nQ 8.5 64.0625 14.71875 69.140625 \nQ 20.953125 74.21875 31.78125 74.21875 \nQ 42.671875 74.21875 48.875 69.140625 \nQ 55.078125 64.0625 55.078125 55.328125 \nQ 55.078125 49.078125 51.53125 44.71875 \nQ 48 40.375 41.703125 38.8125 \nQ 48.828125 37.15625 52.796875 32.3125 \nQ 56.78125 27.484375 56.78125 20.515625 \nQ 56.78125 9.90625 50.3125 4.234375 \nQ 43.84375 -1.421875 31.78125 -1.421875 \nQ 19.734375 -1.421875 13.25 4.234375 \nQ 6.78125 9.90625 6.78125 20.515625 \nQ 6.78125 27.484375 10.78125 32.3125 \nQ 14.796875 37.15625 21.921875 38.8125 \nz\nM 18.3125 54.390625 \nQ 18.3125 48.734375 21.84375 45.5625 \nQ 25.390625 42.390625 31.78125 42.390625 \nQ 38.140625 42.390625 41.71875 45.5625 \nQ 45.3125 48.734375 45.3125 54.390625 \nQ 45.3125 60.0625 41.71875 63.234375 \nQ 38.140625 66.40625 31.78125 66.40625 \nQ 25.390625 66.40625 21.84375 63.234375 \nQ 18.3125 60.0625 18.3125 54.390625 \nz\n\" id=\"DejaVuSans-56\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-56\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_6\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"346.506818\" xlink:href=\"#ma3f081966e\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 1.0 -->\n      <g transform=\"translate(338.555256 239.238437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 12.40625 8.296875 \nL 28.515625 8.296875 \nL 28.515625 63.921875 \nL 10.984375 60.40625 \nL 10.984375 69.390625 \nL 28.421875 72.90625 \nL 38.28125 72.90625 \nL 38.28125 8.296875 \nL 54.390625 8.296875 \nL 54.390625 0 \nL 12.40625 0 \nz\n\" id=\"DejaVuSans-49\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_7\">\n      <defs>\n       <path d=\"M 0 0 \nL -3.5 0 \n\" id=\"mefe5432a09\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#mefe5432a09\" y=\"214.756364\"/>\n      </g>\n     </g>\n     <g id=\"text_7\">\n      <!-- 0 -->\n      <g transform=\"translate(13.5625 218.555582)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_8\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#mefe5432a09\" y=\"186.140305\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- 5 -->\n      <g transform=\"translate(13.5625 189.939524)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 10.796875 72.90625 \nL 49.515625 72.90625 \nL 49.515625 64.59375 \nL 19.828125 64.59375 \nL 19.828125 46.734375 \nQ 21.96875 47.46875 24.109375 47.828125 \nQ 26.265625 48.1875 28.421875 48.1875 \nQ 40.625 48.1875 47.75 41.5 \nQ 54.890625 34.8125 54.890625 23.390625 \nQ 54.890625 11.625 47.5625 5.09375 \nQ 40.234375 -1.421875 26.90625 -1.421875 \nQ 22.3125 -1.421875 17.546875 -0.640625 \nQ 12.796875 0.140625 7.71875 1.703125 \nL 7.71875 11.625 \nQ 12.109375 9.234375 16.796875 8.0625 \nQ 21.484375 6.890625 26.703125 6.890625 \nQ 35.15625 6.890625 40.078125 11.328125 \nQ 45.015625 15.765625 45.015625 23.390625 \nQ 45.015625 31 40.078125 35.4375 \nQ 35.15625 39.890625 26.703125 39.890625 \nQ 22.75 39.890625 18.8125 39.015625 \nQ 14.890625 38.140625 10.796875 36.28125 \nz\n\" id=\"DejaVuSans-53\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_9\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#mefe5432a09\" y=\"157.524247\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 10 -->\n      <g transform=\"translate(7.2 161.323466)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_10\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#mefe5432a09\" y=\"128.908189\"/>\n      </g>\n     </g>\n     <g id=\"text_10\">\n      <!-- 15 -->\n      <g transform=\"translate(7.2 132.707408)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_11\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#mefe5432a09\" y=\"100.292131\"/>\n      </g>\n     </g>\n     <g id=\"text_11\">\n      <!-- 20 -->\n      <g transform=\"translate(7.2 104.091349)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_6\">\n     <g id=\"line2d_12\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#mefe5432a09\" y=\"71.676073\"/>\n      </g>\n     </g>\n     <g id=\"text_12\">\n      <!-- 25 -->\n      <g transform=\"translate(7.2 75.475291)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_7\">\n     <g id=\"line2d_13\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#mefe5432a09\" y=\"43.060014\"/>\n      </g>\n     </g>\n     <g id=\"text_13\">\n      <!-- 30 -->\n      <g transform=\"translate(7.2 46.859233)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 40.578125 39.3125 \nQ 47.65625 37.796875 51.625 33 \nQ 55.609375 28.21875 55.609375 21.1875 \nQ 55.609375 10.40625 48.1875 4.484375 \nQ 40.765625 -1.421875 27.09375 -1.421875 \nQ 22.515625 -1.421875 17.65625 -0.515625 \nQ 12.796875 0.390625 7.625 2.203125 \nL 7.625 11.71875 \nQ 11.71875 9.328125 16.59375 8.109375 \nQ 21.484375 6.890625 26.8125 6.890625 \nQ 36.078125 6.890625 40.9375 10.546875 \nQ 45.796875 14.203125 45.796875 21.1875 \nQ 45.796875 27.640625 41.28125 31.265625 \nQ 36.765625 34.90625 28.71875 34.90625 \nL 20.21875 34.90625 \nL 20.21875 43.015625 \nL 29.109375 43.015625 \nQ 36.375 43.015625 40.234375 45.921875 \nQ 44.09375 48.828125 44.09375 54.296875 \nQ 44.09375 59.90625 40.109375 62.90625 \nQ 36.140625 65.921875 28.71875 65.921875 \nQ 24.65625 65.921875 20.015625 65.03125 \nQ 15.375 64.15625 9.8125 62.3125 \nL 9.8125 71.09375 \nQ 15.4375 72.65625 20.34375 73.4375 \nQ 25.25 74.21875 29.59375 74.21875 \nQ 40.828125 74.21875 47.359375 69.109375 \nQ 53.90625 64.015625 53.90625 55.328125 \nQ 53.90625 49.265625 50.4375 45.09375 \nQ 46.96875 40.921875 40.578125 39.3125 \nz\n\" id=\"DejaVuSans-51\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-51\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_8\">\n     <g id=\"line2d_14\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#mefe5432a09\" y=\"14.443956\"/>\n      </g>\n     </g>\n     <g id=\"text_14\">\n      <!-- 35 -->\n      <g transform=\"translate(7.2 18.243175)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-51\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_15\">\n    <path clip-path=\"url(#pd64987c793)\" d=\"M 42.143182 17.083636 \nL 72.579545 201.578182 \nL 103.015909 205.54521 \nL 133.452273 207.865772 \nL 163.888636 209.512238 \nL 194.325 210.789336 \nL 224.761364 211.8328 \nL 255.197727 212.715037 \nL 285.634091 213.479266 \nL 316.070455 214.153363 \nL 346.506818 214.756364 \n\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 26.925 224.64 \nL 26.925 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 361.725 224.64 \nL 361.725 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 26.925 224.64 \nL 361.725 224.64 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 26.925 7.2 \nL 361.725 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"pd64987c793\">\n   <rect height=\"217.44\" width=\"334.8\" x=\"26.925\" y=\"7.2\"/>\n  </clipPath>\n </defs>\n</svg>\n",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "source": [
    "from math import log\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#print(exp)\n",
    "probs = [1e-15, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "#probs = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
    "info = [-log(p) for p in probs] ## Information\n",
    "entropy = -sum([p*log(p) for p in probs]) ## entropy of the distribution\n",
    "plt.plot(probs, info)\n",
    "print(\"entropy: {}\".format(entropy))\n",
    "qprobs = np.abs([prob - 0.15 for prob in probs])\n",
    "cross_entropy = -sum([p*log(q) for p, q in zip(probs, qprobs)]) ## entropy of the distribution\n",
    "print(\"cross entropy: {}\".format(cross_entropy))"
   ]
  },
  {
   "source": [
    "##### 1.4 Confusion Matrix (CM)\n",
    "\n",
    "* The CM measures the performance of a classification model (binary or multiclass setup)\n",
    "\n",
    "* It specifically shows the class confusion by means of True Positive (TP), True Negative (TN), False Positive (FP) and False Negative (FN)s\n",
    "\n",
    "### Binary case\n",
    "\n",
    "* TP: The prediction is positive and true (matches the true label)\n",
    "* TN: The prediction is negative and true \n",
    "* FP: The prediction is positive but not true (not the true label)\n",
    "* FN: The prediction is negative but not true\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": "<img src=\"https://miro.medium.com/max/2400/1*fxiTNIgOyvAombPJx5KGeA.png\" width=\"300\" height=\"300\"/>",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "Image(url= \"https://miro.medium.com/max/2400/1*fxiTNIgOyvAombPJx5KGeA.png\", width=300, height=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[3, 1],\n",
       "       [1, 3]])"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "y_true = [True, False, False, True, True, False, True, False]\n",
    "y_pred = [True, True, False, True, False, False, True, False]\n",
    "confusion_matrix(y_true, y_pred)"
   ]
  },
  {
   "source": [
    "#### 1.4 Confusion Matrix (CM)\n",
    "\n",
    "#### Multiclass case\n",
    "\n",
    "* Similar to the binary case, the multiclass case considers all the classes when calculating TP, TN, FP and FNs\n",
    "\n",
    "* Refernce for the example: https://dev.to/overrideveloper/understanding-the-confusion-matrix-264i\n",
    "\n",
    "* E.g. Take the following confusion matrix:\n",
    "\n",
    "    <img src=\"https://res.cloudinary.com/practicaldev/image/fetch/s--cRGF5_MX--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://thepracticaldev.s3.amazonaws.com/i/hri4evvbu1t2v7mmmvct.png\" alt=\"drawing\" width=\"300\"/>\n",
    "\n",
    "#### True Positive \n",
    "\n",
    "* The TPs in this case represents the correctly classified samples. They are the once in the diagonal:\n",
    "\n",
    "    * $TP_{total} = P_{GG} + P_{MM} + P_{SS}$\n",
    "\n",
    "#### True Negatives\n",
    "\n",
    "* TNs for each class can be seen as follows,\n",
    "    * For the grayhound class $TN_{grayhound} = P_{MM} + P_{SM} + P_{MS} + P_{SS}$\n",
    "\n",
    "    * <img src=\"https://res.cloudinary.com/practicaldev/image/fetch/s--Ps4NK1D6--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://thepracticaldev.s3.amazonaws.com/i/wn6xmsa03jt6q5uxpyhv.png\" alt=\"drawing\" width=\"300\"/>\n",
    "\n",
    "    * For the mastiff class $TN_{mastiff} = P_{GG} + P_{SG} + P_{GS} + P_{SS}$\n",
    "    \n",
    "    * <img src=\"https://res.cloudinary.com/practicaldev/image/fetch/s--Gt_FzbqX--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://thepracticaldev.s3.amazonaws.com/i/59757aql6m5rnv3b1cqo.png\" alt=\"drawing\" width=\"300\"/>\n",
    "\n",
    "    * For the samoyed class $TN_{samoyed} = P_{GG} + P_{MG} + P_{GM} + P_{MM}$\n",
    "    \n",
    "    * <img src=\"https://res.cloudinary.com/practicaldev/image/fetch/s--qlCarH7U--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://thepracticaldev.s3.amazonaws.com/i/zmli0399jpwjmgrbjgh6.png\" alt=\"drawing\" width=\"300\"/>\n",
    "\n",
    "    * So the total number of true negatives are: $TN_{total} = TN_{grayhound} + TN_{mastiff} + TN_{samoyed}$\n",
    "\n",
    "#### False Positives\n",
    "\n",
    "* FPs in multiclass case: The number of samples from other classes that are predicted as the subjected class\n",
    "\n",
    "    * For the grayhound class $FP_{grayhound} = P_{GM} + P_{GS}$\n",
    "\n",
    "    * <img src=\"https://res.cloudinary.com/practicaldev/image/fetch/s--628wJA9p--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://thepracticaldev.s3.amazonaws.com/i/mfd9j7yq5v4i797z3a0e.png\" alt=\"drawing\" width=\"300\"/>\n",
    "\n",
    "    * For the mastiff class $FP_{mastiff} = P_{MG} + P_{MS}$\n",
    "\n",
    "    * <img src=\"https://res.cloudinary.com/practicaldev/image/fetch/s--YUU4QJhi--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://thepracticaldev.s3.amazonaws.com/i/nghrfl7wqguyhvk01kag.png\" alt=\"drawing\" width=\"300\"/>\n",
    "\n",
    "    * For the samoyed class $FP_{samoyed} = P_{SG} + P_{SM}$\n",
    "\n",
    "    * <img src=\"https://res.cloudinary.com/practicaldev/image/fetch/s--3QUKW-Sp--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://thepracticaldev.s3.amazonaws.com/i/e6gfhvxnh3l532paoju6.png\" alt=\"drawing\" width=\"300\"/>\n",
    "\n",
    "    * So the total number of FPs are: $FP_{total} = FP_{grayhound} + FP_{mastiff} + FP_{samoyed} $\n",
    "\n",
    "#### False Negatives\n",
    "\n",
    "* FNs in the multiclass case: The number of samples from a ground truth class that are classified as other classes\n",
    "\n",
    "    * For the grayhound class $FN_{grayhound} = P_{MG} + P_{SG} $\n",
    "\n",
    "    * <img src=\"https://res.cloudinary.com/practicaldev/image/fetch/s--QpG8_xwv--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://thepracticaldev.s3.amazonaws.com/i/x1ufhj99p00c3eynsw2q.png\" alt=\"drawing\" width=\"300\"/>\n",
    "\n",
    "    * For the mastiff class $FN_{mastiff} = P_{GM} + P_{SM} $\n",
    "\n",
    "    * <img src=\"https://res.cloudinary.com/practicaldev/image/fetch/s--L_S_v5uG--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://thepracticaldev.s3.amazonaws.com/i/kxb9eu9wa48v1kyknv10.png\" alt=\"drawing\" width=\"300\"/>\n",
    "\n",
    "    * For the mastiff class $FN_{samoyed} = P_{GS} + P_{MS} $\n",
    "\n",
    "    * <img src=\"https://res.cloudinary.com/practicaldev/image/fetch/s--zBCKbcHF--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://thepracticaldev.s3.amazonaws.com/i/7tr1hsadrkm6ckrax4ia.png\" alt=\"drawing\" width=\"300\"/>\n",
    "\n",
    "    * The number of total FNs are: $FN_{total} = FN_{grayhound} + FN_{mastiff} + FN_{samoyed} $\n",
    "\n",
    "\n",
    "\n",
    "    "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[3, 0, 0],\n",
       "       [0, 3, 0],\n",
       "       [0, 0, 3]])"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "## Take 9 samples that would belong to one of the 3 classes\n",
    "y_true = [0, 2, 1, 0, 2, 0, 2, 1, 1]\n",
    "y_pred = [0, 2, 1, 0, 2, 0, 2, 1, 1]\n",
    "confusion_matrix(y_true, y_pred)"
   ]
  },
  {
   "source": [
    "### 1.5 Accuracy, Precision and Recall\n",
    "\n",
    "#### Accuracy\n",
    "\n",
    "* The model accuracy simply is the ratio between the total number of correct classifications and total number of classification\n",
    "\n",
    "    * $Accuracy = \\dfrac {TP_{total}} {TOTAL}$ where $TOTAL$ is the total number of classifications\n",
    "        * In above example $TOTAL = P_{GG} + P_{MG} + P_{SG} + P_{GM} + P_{MM} + P_{SM} + P_{GS} + P_{MS} + P_{SS}$\n",
    "\n",
    "    * Accuracy shows how often the classifier is correct in prediction\n",
    "\n",
    "    * However accuracy does not reflect the true capability of a classifier (very sensitive to class imbalances)\n",
    "\n",
    "#### Precision\n",
    "\n",
    "* Precision of a given class measures the accuracy of that class given the total number of predictions in that class\n",
    "\n",
    "    * $Precision = \\dfrac {TP} {TP + FP}$\n",
    "\n",
    "#### Recall\n",
    "\n",
    "* Recall quantifies the ability of a model to classify the relevent samples in a dataset. This gives an indication on the coverage of a given class\n",
    "\n",
    "    * $Recall = \\dfrac {TP} {TP + FN}$\n",
    "\n",
    "    * Recall is also known as the sensitive of the model\n",
    "\n",
    "*Precision and recall can be related to each other inversely*\n",
    "\n",
    "#### Average of Precision and Recall in multiclass classification\n",
    "\n",
    "* There are two types of averaging methods:\n",
    "\n",
    "    * Macro average: $Precision_{macro} = \\dfrac {Precision_{total}} {N}$\n",
    "\n",
    "    * Micro average: $Precision_{micro} = \\dfrac {TP_{total}} {TP_{total} + FP_{total}} $\n",
    "\n",
    "* Ref: https://machinelearningmastery.com/precision-recall-and-f-measure-for-imbalanced-classification/#:~:text=Recall%20for%20Multi%2DClass%20Classification&text=binary%20classification%20problems.-,In%20an%20imbalanced%20classification%20problem%20with%20more%20than%20two%20classes,false%20negatives%20across%20all%20classes."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### 1.6 Reciever Characteristic Operator (ROC) curve\n",
    "\n",
    "* The ROC is originaly an evaluation metric for binary classification \n",
    "\n",
    "* ROC is plot of recall against the false positive rate at different thresholds\n",
    "\n",
    "* It is used to find an optimal threshold that balances the recall and false positive rate\n",
    "\n",
    "* The area under the ROC curve (AUC) measures the ability of a classifier to distinguish between the classes\n",
    "\n",
    "* Specificity of a model: How many TN samples got correctly classified out of all negative classifications\n",
    "    * $Specificity = \\dfrac {TN}{TN + FP}$\n",
    "\n",
    "* False Positve Rate (FPR): rate of negative samples classified as positive\n",
    "    * $FPR = \\dfrac {FP}{FP + TN} = 1 - Specificity$\n",
    "\n",
    "#### Prediction probability at different thresholds\n",
    "\n",
    "* Following table shows the measurement metrics for different thresholds\n",
    "example ref: https://www.analyticsvidhya.com/blog/2020/06/auc-roc-curve-machine-learning/\n",
    "\n",
    "* <img src=\"https://cdn.analyticsvidhya.com/wp-content/uploads/2020/06/data-1.png\" alt=\"drawing\" width=\"300\"/>\n",
    "\n",
    "#### Intepretation of ROC through AOU\n",
    "\n",
    "* Case-1 $AOU = 1$ gives a model that classifies all the positive and negative classes correctly\n",
    "\n",
    "    * <img src=\"https://cdn.analyticsvidhya.com/wp-content/uploads/2020/06/AUC1.png\" alt=\"drawing\" width=\"100\"/>\n",
    "\n",
    "* Case-2 $AOU = 0$ means all the positive samples classified as negatives and vice versa\n",
    "\n",
    "* Case-3 $0.5 < AOU < 1$ large portion of TP and TN compared to FP and FNs\n",
    "\n",
    "    * <img src=\"https://cdn.analyticsvidhya.com/wp-content/uploads/2020/06/AUC3.png\" alt=\"drawing\" width=\"100\"/>\n",
    "\n",
    "* Case-4 $AOU = 0.5$ Classifier cannot distinguish the positive and negative classes properly (a random classifier)\n",
    "\n",
    "    * <img src=\"https://cdn.analyticsvidhya.com/wp-content/uploads/2020/06/AUC2.png\" alt=\"drawing\" width=\"100\"/>\n",
    "\n",
    "    * In this case the $Recall = FPR$; The propotion of correct and incorrect classifications are the same\n",
    "\n",
    "* Finding an optimal threshold means that, finding the point in ROC curve where Recall and Specificity are the highest\n",
    "\n",
    "#### ROC for multiclass case\n",
    "\n",
    "* In multiclass case, a one vs all approach can be used:\n",
    "    * ROC for class-1: Class-1 vs Class-2 and 3\n",
    "\n",
    "    * ROC for class-2: Class-1 vs Class-1 and 3\n",
    "    \n",
    "    * ROC for class-3: Class-1 vs Class-1 and 2\n",
    "\n",
    "* Keras implementation of binary and multiclass ROC curve calculation: https://github.com/Tony607/ROC-Keras/blob/master/ROC-Keras.ipynb\n",
    "* Keras classification metrics doc: https://keras.io/api/metrics/classification_metrics/\n",
    "* Detailed example of ROC: \n",
    "    * https://www.youtube.com/watch?v=4jRBRDbJemM&t=2s\n",
    "    * https://www.analyticsvidhya.com/blog/2020/06/auc-roc-curve-machine-learning/\n",
    "* On optimal threshold:\n",
    "    * https://machinelearningmastery.com/threshold-moving-for-imbalanced-classification/"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 2. Transfer learning in image classification\n",
    "\n",
    "#### From the paper \"How transferable are features in deep neuralnetworks?\"\n",
    "\n",
    "### 2.1 Introduction to transfer learning in deep learning\n",
    "\n",
    "* In the domain of deep learning, the transfer learning involves a source task (A) and an target task (B)\n",
    "\n",
    "* The idea is to learn the features using a source task with large enough dataset and transfer the knowledge to the target task by means of learnt parameters\n",
    "\n",
    "* The transferbility between two tasks could depend on:\n",
    "\n",
    "    * The distance between tasks (how similar they are)\n",
    "    * The point of transfer (till which layer the knowledge is transferable)\n",
    "    * Target dataset size (small dataset could lead to overfitting even in the transfer learning case)\n",
    "\n",
    "* Once the point of transfer is determined ($N^{th}$ layer), either the transfered features are frozen or fine tuned for the target task\n",
    "\n",
    "#### Generality and Specificity of a layer\n",
    "\n",
    "* General features: Features that are common between tasks\n",
    "\n",
    "* Specific features: Features that are task specific \n",
    "\n",
    "* The early layers (near input) of a deep convolutional neural network learns generalizable features such as color blobs, edges and corners\n",
    "\n",
    "* The later the layer is the generalizability drops and specificity increases (learns high level concepts such as full shapes)\n",
    "\n",
    "### 2.2 Transfer learning experiment setup\n",
    "\n",
    "* Two tasks are considered: source task A and target task B\n",
    "\n",
    "    * Task A has large number of data and Task B has small number of data\n",
    "\n",
    "* Considered scenarios: \n",
    "    \n",
    "    * Scenario-1: Task A and B are very similar\n",
    "        \n",
    "        * Imagenet dataset split according to types of cats and dogs (similar domain)\n",
    "\n",
    "    * Scenario-2: Task A and B are very different\n",
    "\n",
    "        * Imagenet dataset split between manmade and natural images (different domains)\n",
    "    \n",
    "* A Neural Network with 7 layers is used to train on both the tasks\n",
    "\n",
    "* Train setup-1: \n",
    "\n",
    "    * Train on task B itself and transfer the generalizable feature and train further on the same task\n",
    "\n",
    "    * Task B training (Fig-2.1)\n",
    "\n",
    "    * <img src=\"./presentation_images/Screenshot from 2021-01-11 09-17-55.png\" alt=\"drawing\" width=\"300\"/>\n",
    "\n",
    "    * Transfer from task B to itself for further training (Fig-2.2)\n",
    "\n",
    "    * <img src=\"./presentation_images/Screenshot from 2021-01-11 09-18-08.png\" alt=\"drawing\" width=\"300\"/>\n",
    "    \n",
    "* Train setup-2:\n",
    "\n",
    "    * Train on the task A (large dataset), transfer the generalizable features to task B and train further\n",
    "\n",
    "    * Task A training (Fig-2.3)\n",
    "\n",
    "    * <img src=\"./presentation_images/Screenshot from 2021-01-11 09-13-51.png\" alt=\"drawing\" width=\"300\"/>\n",
    "\n",
    "    * Transfer from task A to B (Fig-2.4)\n",
    "\n",
    "    * <img src=\"./presentation_images/Screenshot from 2021-01-11 09-16-53.png\" alt=\"drawing\" width=\"300\"/>\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### 2.3 Experiment results and discussion\n",
    "\n",
    "#### Similar domain case:\n",
    "\n",
    "* The following plots show the top-1 accuracies for the task B validation set\n",
    "\n",
    "* <img src=\"./presentation_images/Screenshot from 2021-01-11 09-29-33.png\" alt=\"drawing\" width=\"300\"/>\n",
    "\n",
    "* White dots: The base accuracy for task B validation is 62.5% when only trained on task B (Fig-2.1)\n",
    "\n",
    "* Solid blue dot: Freeze the first 3 layers, initialize the rest of the layers randomly (Fig-2.2)\n",
    "    \n",
    "    * The results here shows, that for the first 3 layers we have similar accuracies as expected (Because of generalizability)\n",
    "\n",
    "    * But the drop after layer 4 indicates the co-adaptive features. The co-adaptive features are the features that depends/has a relationship to preceeding layers\n",
    "\n",
    "    * However, from layer 6-8 the accuracy again recovers indicating these layers are free of co-adaptive features \n",
    "\n",
    "* Blue dot with a +: The frozen layers are also further trained along with the randomly initialized layers (Fig-2.2)\n",
    "\n",
    "    * The performance here is similar to the base accuracy since the scenario itself is similar to the task B only training (the base case)\n",
    "\n",
    "* Red diamonds: first 3 layers are trasfered from task A to B and frozen (Fig-2.4)\n",
    "\n",
    "    * Here shows clearly the generalizability between tasks\n",
    "\n",
    "    * The performance when only the first 3 layers are frozen gives similar accuracies as trained on task B iteself(generalizability)\n",
    "\n",
    "    * But after the layer 3 the performance drops significantly as the number of co-adaptive and specific features dominates the generalizable features\n",
    "\n",
    "* Red diamonds with a +: Similar to the previous case, but the transfered features of task A further fine tuned (Fig-2.4)\n",
    "\n",
    "    * This results suggests that, when fine tuned after transfering from a different domain could lead to better generalization compared to all the method discussed above\n",
    "    \n",
    "    * Be aware that depending on the size of the target dataset, there is a potential that this could lead to an overfitting\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### 2.3 Experiment results and discussion\n",
    "\n",
    "#### Different domain case:\n",
    "\n",
    "* The following results are plotted according the pneumonia classification experiments\n",
    "\n",
    "    * Both binary classification (pneumonia or normal)\n",
    "    \n",
    "    * multi-class classification (pneumonia-bacteria, pneumonia-viral and normal)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}